{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c1da168c",
      "metadata": {},
      "source": [
        "# Build Dictionary Notebook\n",
        "\n",
        "This notebook replicates the functionality of `scripts/build_dictionary.py`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b813056",
      "metadata": {},
      "source": [
        "## 1.a Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b314c29",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# allow importing from scripts directory\n",
        "sys.path.append('scripts')\n",
        "from build_dictionary import gather_files, build_vocabulary, read_extra_stopwords\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be1fd853",
      "metadata": {},
      "source": [
        "## 1.b Configure input and output paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46ff2cac",
      "metadata": {},
      "outputs": [],
      "source": [
        "policy_documents_path = 'Policy-documents'\n",
        "policy_dictionary_output = 'policy_dictionary.txt'\n",
        "\n",
        "# Example for theory documents\n",
        "theory_documents_path = 'sources'\n",
        "theory_dictionary_output = 'theory_dictionary.txt'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd231c91",
      "metadata": {},
      "source": [
        "## 1.c Set processing options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01f2aba7",
      "metadata": {},
      "outputs": [],
      "source": [
        "language = 'dutch'\n",
        "extra_stopwords_path = 'stopwords_extra.txt'\n",
        "use_stemming = True\n",
        "min_frequency = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f672d94d",
      "metadata": {},
      "source": [
        "## 2.a Prepare stop words and stemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ad140c0",
      "metadata": {},
      "outputs": [],
      "source": [
        "nltk.download('stopwords', quiet=True)\n",
        "stop_words = set(stopwords.words(language))\n",
        "stop_words.update(read_extra_stopwords(extra_stopwords_path))\n",
        "stemmer = SnowballStemmer(language) if use_stemming else None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14e4d1f0",
      "metadata": {},
      "source": [
        "## 2.b Build vocabulary from the documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25c67826",
      "metadata": {},
      "outputs": [],
      "source": [
        "files = gather_files(policy_documents_path)\n",
        "policy_vocab = build_vocabulary(files, stop_words, stemmer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81bf5303",
      "metadata": {},
      "source": [
        "## 2.c Save the dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14c992a4",
      "metadata": {},
      "outputs": [],
      "source": [
        "words = sorted([w for w, c in policy_vocab.items() if c >= min_frequency])\n",
        "with open(policy_dictionary_output, 'w', encoding='utf-8') as fh:\n",
        "    for w in words:\n",
        "        fh.write(f'{w}\n",
        "')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
