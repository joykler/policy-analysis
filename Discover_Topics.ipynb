{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5d7d70c2",
      "metadata": {},
      "source": [
        "# Discover Topics Notebook\n",
        "\n",
        "This notebook mirrors `scripts/discover_topics.py` for LDA topic modeling."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bdfe7fe",
      "metadata": {},
      "source": [
        "## 1.a Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdd22dea",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "sys.path.append('scripts')\n",
        "from discover_topics import gather_files, build_corpus, discover_topics, read_extra_stopwords\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2616c2f4",
      "metadata": {},
      "source": [
        "## 1.b Configure paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd3d73c9",
      "metadata": {},
      "outputs": [],
      "source": [
        "policydocument_path = 'Policy-documents'\n",
        "slaverydocument_path = 'sources'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17705261",
      "metadata": {},
      "source": [
        "## 1.c Choose parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bd5e6c1",
      "metadata": {},
      "outputs": [],
      "source": [
        "language = 'dutch'\n",
        "extra_stopwords_path = 'stopwords_extra.txt'\n",
        "use_stemming = True\n",
        "num_topics = 5\n",
        "passes = 5\n",
        "words_per_topic = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd32c96e",
      "metadata": {},
      "source": [
        "## 2.a Prepare stop words and stemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d094a63",
      "metadata": {},
      "outputs": [],
      "source": [
        "nltk.download('stopwords', quiet=True)\n",
        "stop_words = set(stopwords.words(language))\n",
        "stop_words.update(read_extra_stopwords(extra_stopwords_path))\n",
        "stemmer = SnowballStemmer(language) if use_stemming else None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0b460a9",
      "metadata": {},
      "source": [
        "## 2.b Build the corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd91964e",
      "metadata": {},
      "outputs": [],
      "source": [
        "files = gather_files(policydocument_path)\n",
        "corpus, dictionary = build_corpus(files, stop_words, stemmer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6a46fe3",
      "metadata": {},
      "source": [
        "## 2.c Train the LDA model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fce53417",
      "metadata": {},
      "outputs": [],
      "source": [
        "lda = discover_topics(corpus, dictionary, num_topics, passes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b766f7b5",
      "metadata": {},
      "source": [
        "## 2.d Display topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59a691c4",
      "metadata": {},
      "outputs": [],
      "source": [
        "for i, topic in lda.show_topics(num_topics=num_topics, num_words=words_per_topic, formatted=False):\n",
        "    print(f'Topic {i}: {', '.join(w for w, _ in topic)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.e Filter dominating terms",
        "",
        "Use `filter_common_terms` to drop words shared across many topics so unique themes are easier to spot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "drop_common_threshold = 10\n",
        "topic_words = extract_topic_words(lda, words_per_topic)\n",
        "filtered_topics = filter_common_terms(topic_words, drop_common_threshold)\n",
        "for i, words in filtered_topics.items():\n",
        "    print(f'Filtered Topic {i}: {', '.join(words)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.f Save topic dictionaries",
        "",
        "Label topics and save their word lists for later use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from topic_dictionary import save_topic_words\n",
        "policy_topic_labels = ['policy_topic1', 'policy_topic2', 'policy_topic3', 'policy_topic4', 'policy_topic5']\n",
        "dictionary_output_dir = 'Policy_topic_dictionaries'\n",
        "save_topic_words(filtered_topics, policy_topic_labels, dictionary_output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.a Evaluate coherence",
        "",
        "Use Gensim's `CoherenceModel` to measure how well the topics hold together. Higher scores typically indicate clearer themes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from gensim.models import CoherenceModel\n",
        "texts = [tokenize(clean_text(extract_text_from_file(f)), stop_words, stemmer) for f in files]\n",
        "coherence_model = CoherenceModel(topics=[filtered_topics[i] for i in range(len(filtered_topics))], texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "coherence = coherence_model.get_coherence()\n",
        "print(f'Coherence: {coherence:.4f}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
